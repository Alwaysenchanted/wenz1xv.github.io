<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>python3爬取淘宝搜索 | wenz</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="JS学习刚刚开始中，因为一些奇怪的原因，对爬虫感兴趣，然后就想着能不能写一个爬淘宝商品的python。python语法0基础，在看别人的代码中借鉴学习，甚至对http什么的都没什么了解。愣头青丝毫不怵，反正就凑出来这个代码。">
<meta name="keywords" content="python3">
<meta property="og:type" content="article">
<meta property="og:title" content="python3爬取淘宝搜索">
<meta property="og:url" content="http://yoursite.com/child/2019/04/08/python1/index.html">
<meta property="og:site_name" content="wenz">
<meta property="og:description" content="JS学习刚刚开始中，因为一些奇怪的原因，对爬虫感兴趣，然后就想着能不能写一个爬淘宝商品的python。python语法0基础，在看别人的代码中借鉴学习，甚至对http什么的都没什么了解。愣头青丝毫不怵，反正就凑出来这个代码。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-04-08T07:35:23.203Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python3爬取淘宝搜索">
<meta name="twitter:description" content="JS学习刚刚开始中，因为一些奇怪的原因，对爬虫感兴趣，然后就想着能不能写一个爬淘宝商品的python。python语法0基础，在看别人的代码中借鉴学习，甚至对http什么的都没什么了解。愣头青丝毫不怵，反正就凑出来这个代码。">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">wenz</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">徐文展的博客</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com/child"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/08/python1/" class="article-date">
  <time datetime="2019-04-08T07:34:00.342Z" itemprop="datePublished">2019-04-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python3爬取淘宝搜索
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>JS学习刚刚开始中，因为一些奇怪的原因，对爬虫感兴趣，然后就想着能不能写一个爬淘宝商品的python。<br>python语法0基础，在看别人的代码中借鉴学习，甚至对http什么的都没什么了解。<br>愣头青丝毫不怵，反正就凑出来这个代码。</p>
<a id="more"></a>
<p>##使用的软件</p>
<ul>
<li>vscode</li>
<li>Chrome<br>##实现代码</li>
</ul>
<p>#####v1 手动传入cookies版本</p>
<blockquote>
<p>一开始写的是通过手动传入cookies<br>解决淘宝要登陆才能搜索的限制<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import xlwt</span><br><span class="line"></span><br><span class="line">def writeExcel(ilt,name):</span><br><span class="line">    if(name != &apos;&apos;):</span><br><span class="line">        count = 0</span><br><span class="line">        workbook = xlwt.Workbook(encoding= &apos;utf-8&apos;)</span><br><span class="line">        worksheet = workbook.add_sheet(&apos;temp&apos;)</span><br><span class="line">        worksheet.write(count,0,&apos;序号&apos;)</span><br><span class="line">        worksheet.write(count,1,&apos;购买&apos;)</span><br><span class="line">        worksheet.write(count,2,&apos;价格&apos;)</span><br><span class="line">        worksheet.write(count,3,&apos;描述&apos;)</span><br><span class="line">        for g in ilt:</span><br><span class="line">            count = count + 1</span><br><span class="line">            worksheet.write(count,0,count)</span><br><span class="line">            worksheet.write(count,1,g[0])</span><br><span class="line">            worksheet.write(count,2,g[1])</span><br><span class="line">            worksheet.write(count,3,g[2])</span><br><span class="line">        workbook.save(name+&apos;.xls&apos;)</span><br><span class="line">        print(&apos;已保存为&apos;+name+&apos;.xls&apos;)</span><br><span class="line">    else:</span><br><span class="line">        printGoodsList(ilt)</span><br><span class="line"></span><br><span class="line">def getHTMLText(url,cookies):</span><br><span class="line">    kv = &#123;&apos;cookie&apos;:cookies,&apos;user-agent&apos;:&apos;Mozilla/5.0&apos;&#125;</span><br><span class="line">    try:</span><br><span class="line">        r = requests.get(url,headers=kv, timeout=30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line">     </span><br><span class="line">def parsePage(ilt, html):</span><br><span class="line">    try:</span><br><span class="line">        plt = re.findall(r&apos;\&quot;view_price\&quot;\:\&quot;[\d\.]*\&quot;&apos;,html)</span><br><span class="line">        tlt = re.findall(r&apos;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&apos;,html)</span><br><span class="line">        sls = re.findall(r&apos;\&quot;view_sales\&quot;\:\&quot;.*?\&quot;&apos;,html)</span><br><span class="line">        for i in range(len(plt)):</span><br><span class="line">            sales = eval(sls[i].split(&apos;:&apos;)[1])</span><br><span class="line">            price = eval(plt[i].split(&apos;:&apos;)[1])</span><br><span class="line">            title = eval(tlt[i].split(&apos;:&apos;)[1])</span><br><span class="line">            ilt.append([sales , price , title])</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;&quot;)</span><br><span class="line"> </span><br><span class="line">def printGoodsList(ilt):</span><br><span class="line">    tplt = &quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;\t&#123;:32&#125;&quot;</span><br><span class="line">    print(tplt.format(&quot;序号&quot;, &quot;购买&quot;,&quot;价格&quot;, &quot;商品名称&quot;))</span><br><span class="line">    count = 0</span><br><span class="line">    for g in ilt:</span><br><span class="line">        count = count + 1</span><br><span class="line">        print(tplt.format(count, g[0], g[1],g[2]))</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    cookies = input(&apos;传入cookies:&apos;)</span><br><span class="line">    goods = input(&apos;搜索商品:&apos;)</span><br><span class="line">    depth = int(input(&apos;搜索页数:&apos;))</span><br><span class="line">    name = input(&apos;输入保存的excel名称(留空print):&apos;)</span><br><span class="line">    start_url = &apos;https://s.taobao.com/search?q=&apos; + goods</span><br><span class="line">    infoList = []</span><br><span class="line">    print(&apos;处理中...&apos;)</span><br><span class="line">    for i in range(depth):</span><br><span class="line">        try:</span><br><span class="line">            url = start_url + &apos;&amp;s=&apos; + str(44*i)</span><br><span class="line">            html = getHTMLText(url,cookies)</span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">            print(&apos;第%i页成功&apos; %(i+1))</span><br><span class="line">        except:</span><br><span class="line">            continue</span><br><span class="line">    writeExcel(infoList,name)</span><br><span class="line">    print(&apos;完成!&apos;)</span><br><span class="line">     </span><br><span class="line">main()</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>找了一些网上的类似py程序，觉得他们的描述有点…奇怪？<br>(可能他们扒的是评论吧，评论好像是js传入)</p>
<p>搜索页面好像结构很简单，url都直接传入中文。<br>当时也没什么好办法解决cookies的问题，模拟登陆感觉又很麻烦。<br>就留了个input给cookies手动传入。</p>
<p>#####用到的库</p>
<ul>
<li>re 正则表达式 内置的</li>
<li>requests 我安装的第一个库，用来处理http请求的（大概）</li>
<li>xlwt 这是个处理excel文件的库<br>#####函数部分<blockquote>
<p>拿网页</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def getHTMLText(url,cookies):</span><br><span class="line">    kv = &#123;&apos;cookie&apos;:cookies,&apos;user-agent&apos;:&apos;Mozilla/5.0&apos;&#125;</span><br><span class="line">    try:</span><br><span class="line">        r = requests.get(url,headers=kv, timeout=30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<p>头文件是kv，里面就一个cookies和user-agent，给request加了个timeout参数。<br>用的函数 requests.get()<br>我目前知道的参数还有params，这个是加在url后面的。<br>url是目标网址，传入的是’<a href="https://s.taobao.com/search?q=商品名字&#39;" target="_blank" rel="noopener">https://s.taobao.com/search?q=商品名字&#39;</a><br>headers是http请求的头文件。<br>这里我又接触了一点点点点的JSON，还未学习。<br>r.raise_for_status()应该是用来抛出异常的。<br>成功的请求r.status_code的值是200。<br>requests的对象有个text，就是拿到的文本文件。</p>
<blockquote>
<p>处理内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def parsePage(ilt, html):</span><br><span class="line">    try:</span><br><span class="line">        plt = re.findall(r&apos;\&quot;view_price\&quot;\:\&quot;[\d\.]*\&quot;&apos;,html)</span><br><span class="line">        tlt = re.findall(r&apos;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&apos;,html)</span><br><span class="line">        sls = re.findall(r&apos;\&quot;view_sales\&quot;\:\&quot;.*?\&quot;&apos;,html)</span><br><span class="line">        for i in range(len(plt)):</span><br><span class="line">            sales = eval(sls[i].split(&apos;:&apos;)[1])</span><br><span class="line">            price = eval(plt[i].split(&apos;:&apos;)[1])</span><br><span class="line">            title = eval(tlt[i].split(&apos;:&apos;)[1])</span><br><span class="line">            ilt.append([sales , price , title])</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;&quot;)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>对page的处理，用正则re.findall匹配html里含有view_prive等内容的部分，取出来的是个数组，然后写个循环把每项都放到之前声明好的ilt数组里。<br>python的for循环好像都是in？然后用range()里放数字进行数字循环，用len()里放数组读数组长度。还是挺好理解的，纪念一下理解的第一个python循环。</p>
<blockquote>
<p>写结果到excel/直接打印结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">def writeExcel(ilt,name):</span><br><span class="line">    if(name != &apos;&apos;):</span><br><span class="line">        count = 0</span><br><span class="line">        workbook = xlwt.Workbook(encoding= &apos;utf-8&apos;)</span><br><span class="line">        worksheet = workbook.add_sheet(&apos;temp&apos;)</span><br><span class="line">        worksheet.write(count,0,&apos;序号&apos;)</span><br><span class="line">        worksheet.write(count,1,&apos;购买&apos;)</span><br><span class="line">        worksheet.write(count,2,&apos;价格&apos;)</span><br><span class="line">        worksheet.write(count,3,&apos;描述&apos;)</span><br><span class="line">        for g in ilt:</span><br><span class="line">            count = count + 1</span><br><span class="line">            worksheet.write(count,0,count)</span><br><span class="line">            worksheet.write(count,1,g[0])</span><br><span class="line">            worksheet.write(count,2,g[1])</span><br><span class="line">            worksheet.write(count,3,g[2])</span><br><span class="line">        workbook.save(name+&apos;.xls&apos;)</span><br><span class="line">        print(&apos;已保存为&apos;+name+&apos;.xls&apos;)</span><br><span class="line">    else:</span><br><span class="line">        printGoodsList(ilt)</span><br><span class="line"></span><br><span class="line">def printGoodsList(ilt):</span><br><span class="line">    tplt = &quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;\t&#123;:32&#125;&quot;</span><br><span class="line">    print(tplt.format(&quot;序号&quot;, &quot;购买&quot;,&quot;价格&quot;, &quot;商品名称&quot;))</span><br><span class="line">    count = 0</span><br><span class="line">    for g in ilt:</span><br><span class="line">        count = count + 1</span><br><span class="line">        print(tplt.format(count, g[0], g[1],g[2]))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>在输入时input设置了一项是excel的名称，如果留空的话就转到print直接打印在屏幕上。这个xlwt库我也是边看边写。<br>就会用三个函数 :</p>
<ul>
<li>workbook = xlwt.Workbook(encoding = ‘UTF-8’)</li>
<li>wirksheet = workbook.add_sheet(‘temp)</li>
<li>worksheet.write()</li>
<li>workbook.save()</li>
</ul>
<p>打开？/创建excel，创建sheet，写入数据，保存表。<br>write有三个参数(行，列，内容)<br>打印用的tplt.format()也差不多吧</p>
<blockquote>
<p>主函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def main():</span><br><span class="line">    cookies = input(&apos;传入cookies:&apos;)</span><br><span class="line">    goods = input(&apos;搜索商品:&apos;)</span><br><span class="line">    depth = int(input(&apos;搜索页数:&apos;))</span><br><span class="line">    name = input(&apos;输入保存的excel名称(留空print):&apos;)</span><br><span class="line">    start_url = &apos;https://s.taobao.com/search?q=&apos; + goods</span><br><span class="line">    infoList = []</span><br><span class="line">    print(&apos;处理中...&apos;)</span><br><span class="line">    for i in range(depth):</span><br><span class="line">        try:</span><br><span class="line">            url = start_url + &apos;&amp;s=&apos; + str(44*i)</span><br><span class="line">            html = getHTMLText(url,cookies)</span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">            print(&apos;第%i页成功&apos; %(i+1))</span><br><span class="line">        except:</span><br><span class="line">            continue</span><br><span class="line">    writeExcel(infoList,name)</span><br><span class="line">    print(&apos;完成!&apos;)</span><br><span class="line">     </span><br><span class="line">main()</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Python 的语法结构好像是先执行没有函数声明def的？<br>然后之前好像还有看到if _ main _ = _ main _ 还是什么的作为程序入口的，不是很懂。反正丢一个main()在那可以运行就行了。</p>
<p>主函数就这样喽，淘宝页面的页数是44*n的，第一页是0，第二页44，第三页88这样，所以这样写的</p>
<p>#####v2 Chrome传入cookies版本</p>
<blockquote>
<p>这个版本多了一个部分，从网上摘了一些代码加进去。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import re</span><br><span class="line">import xlwt</span><br><span class="line">import sqlite3</span><br><span class="line">import requests</span><br><span class="line">from win32.win32crypt import CryptUnprotectData</span><br><span class="line"></span><br><span class="line">def getcookiefromchrome():</span><br><span class="line">    host = &apos;.taobao.com&apos;</span><br><span class="line">    cookies_str = &apos;&apos;</span><br><span class="line">    cookiepath=os.environ[&apos;LOCALAPPDATA&apos;]+r&quot;\Google\Chrome\User Data\Default\Cookies&quot;</span><br><span class="line">    sql=&quot;select host_key,name,encrypted_value from cookies where host_key=&apos;%s&apos;&quot; % host</span><br><span class="line">    with sqlite3.connect(cookiepath) as conn:</span><br><span class="line">        cu=conn.cursor()        </span><br><span class="line">        cookies=&#123;name:CryptUnprotectData(encrypted_value)[1].decode() for host_key,name,encrypted_value in cu.execute(sql).fetchall()&#125;</span><br><span class="line">        for key,values in cookies.items():</span><br><span class="line">                cookies_str = cookies_str + str(key)+&quot;=&quot;+str(values)+&apos;;&apos;</span><br><span class="line">        return cookies_str</span><br><span class="line"></span><br><span class="line">def writeExcel(ilt,name):</span><br><span class="line">    if(name != &apos;&apos;):</span><br><span class="line">        count = 0</span><br><span class="line">        workbook = xlwt.Workbook(encoding= &apos;utf-8&apos;)</span><br><span class="line">        worksheet = workbook.add_sheet(&apos;temp&apos;)</span><br><span class="line">        worksheet.write(count,0,&apos;序号&apos;)</span><br><span class="line">        worksheet.write(count,1,&apos;购买&apos;)</span><br><span class="line">        worksheet.write(count,2,&apos;价格&apos;)</span><br><span class="line">        worksheet.write(count,3,&apos;描述&apos;)</span><br><span class="line">        for g in ilt:</span><br><span class="line">            count = count + 1</span><br><span class="line">            worksheet.write(count,0,count)</span><br><span class="line">            worksheet.write(count,1,g[0])</span><br><span class="line">            worksheet.write(count,2,g[1])</span><br><span class="line">            worksheet.write(count,3,g[2])</span><br><span class="line">        workbook.save(name+&apos;.xls&apos;)</span><br><span class="line">        print(&apos;已保存为：&apos;+name+&apos;.xls&apos;)</span><br><span class="line">    else:</span><br><span class="line">        printGoodsList(ilt)</span><br><span class="line"></span><br><span class="line">def getHTMLText(url):</span><br><span class="line">    cookies = getcookiefromchrome()</span><br><span class="line">    kv = &#123;&apos;cookie&apos;:cookies,&apos;user-agent&apos;:&apos;Mozilla/5.0&apos;&#125;</span><br><span class="line">    try:</span><br><span class="line">        r = requests.get(url,headers=kv, timeout=30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line">     </span><br><span class="line">def parsePage(ilt, html):</span><br><span class="line">    try:</span><br><span class="line">        plt = re.findall(r&apos;\&quot;view_price\&quot;\:\&quot;[\d\.]*\&quot;&apos;,html)</span><br><span class="line">        tlt = re.findall(r&apos;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&apos;,html)</span><br><span class="line">        sls = re.findall(r&apos;\&quot;view_sales\&quot;\:\&quot;.*?\&quot;&apos;,html)</span><br><span class="line">        for i in range(len(plt)):</span><br><span class="line">            sales = eval(sls[i].split(&apos;:&apos;)[1])</span><br><span class="line">            price = eval(plt[i].split(&apos;:&apos;)[1])</span><br><span class="line">            title = eval(tlt[i].split(&apos;:&apos;)[1])</span><br><span class="line">            ilt.append([sales , price , title])</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;&quot;)</span><br><span class="line"> </span><br><span class="line">def printGoodsList(ilt):</span><br><span class="line">    tplt = &quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;\t&#123;:32&#125;&quot;</span><br><span class="line">    print(tplt.format(&quot;序号&quot;, &quot;购买&quot;,&quot;价格&quot;, &quot;商品名称&quot;))</span><br><span class="line">    count = 0</span><br><span class="line">    for g in ilt:</span><br><span class="line">        count = count + 1</span><br><span class="line">        print(tplt.format(count, g[0], g[1],g[2]))</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    goods = input(&apos;搜索商品:&apos;)</span><br><span class="line">    depth = int(input(&apos;搜索页数:&apos;))</span><br><span class="line">    name = input(&apos;输入保存的excel名称(留空print):&apos;)</span><br><span class="line">    start_url = &apos;https://s.taobao.com/search?q=&apos; + goods</span><br><span class="line">    infoList = []</span><br><span class="line">    print(&apos;处理中...&apos;)</span><br><span class="line">    for i in range(depth):</span><br><span class="line">        try:</span><br><span class="line">            url = start_url + &apos;&amp;s=&apos; + str(44*i)</span><br><span class="line">            html = getHTMLText(url)</span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">            print(&apos;第%i页成功...&apos; %(i+1))</span><br><span class="line">        except:</span><br><span class="line">            continue</span><br><span class="line">    writeExcel(infoList,name)</span><br><span class="line">    print(&apos;完成!&apos;)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>这个就多了一个函数，单独看多出来的函数：</p>
<blockquote>
<p>从Chrome拿cookies数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import sqlite3</span><br><span class="line">from win32.win32crypt import CryptUnprotectData</span><br><span class="line"></span><br><span class="line">def getcookiefromchrome():</span><br><span class="line">    host = &apos;.taobao.com&apos;</span><br><span class="line">    cookies_str = &apos;&apos;</span><br><span class="line">    cookiepath=os.environ[&apos;LOCALAPPDATA&apos;]+r&quot;\Google\Chrome\User Data\Default\Cookies&quot;</span><br><span class="line">    sql=&quot;select host_key,name,encrypted_value from cookies where host_key=&apos;%s&apos;&quot; % host</span><br><span class="line">    with sqlite3.connect(cookiepath) as conn:</span><br><span class="line">        cu=conn.cursor()        </span><br><span class="line">        cookies=&#123;name:CryptUnprotectData(encrypted_value)[1].decode() for host_key,name,encrypted_value in cu.execute(sql).fetchall()&#125;</span><br><span class="line">        for key,values in cookies.items():</span><br><span class="line">                cookies_str = cookies_str + str(key)+&quot;=&quot;+str(values)+&apos;;&apos;</span><br><span class="line">        return cookies_str</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>为他导了三个库！<br>我总觉得还有很大的可以优化的空间。<br>而且这个是针对Chrome的cookies缓存位置，没在Chrome登过淘宝就没用了。<br>pywin32我装了好久才成功，他在vscode里还会一直报错，虽然运行不影响。<br>大意应该是打开那个路径，然后解码cookies，然后把他拿出来。</p>
<p>从网上摘的函数是直接return cookies<br>然后放到头文件里发请求，发现拿不到数据！<br>对比一下发现cookies是一个dict，格式跟他要求的好像不一样？<br>我也不会什么字典相关操作，就只能简单的，把key和value用循环拼凑成一个满足cookies条件的str，我总觉得应该是有相关函数的，能省一些循环的资源，不过这样也行。<br>然后再把主函数的cookies部分改一改就成了。</p>
<p>##讨论<br>扒12页没有问题，再多的没有试过。<br>好像据说淘宝有反爬虫？如果爬太多可能拿不到数据？<br>但是好像爬这个的过程，跟人用浏览器访问没什么区别欸？<br>我觉得识别方法可能是同一个IP快速访问多页，这只有爬虫能做到，那加个延时应该能应对，虽然我不知道延时函数怎么写，搜就完事了。</p>
<p>还有看到说淘宝的网页是ajax动态加载的，可是….好像不是欸？（可能是评论吧）</p>
<p>感觉扒评论比较有价值，可以调查一下大家买的都是什么型号这样子。<br>可是想写才发觉，我好像不会python。</p>
<p>我还是老老实实的回去把JS 30天挑战先完成掉吧，然后认真的自己写一个网页，搞明白CSS的各种问题（现在好多搞不灵清），然后去看看Jquery看看PHP，如果有信心完成一个不错的个人网站，那么就去租VPS喽。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/child/2019/04/08/python1/" data-id="cju8ayb7z000ltwrhjybx1oy9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python3/">python3</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/04/08/python0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Python学习指南
        
      </div>
    </a>
  
  
    <a href="/2019/04/08/mysql1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">mysql8安装</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/30daysJS/">30daysJS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/movie/">movie</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python3/">python3</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/30daysJS/" style="font-size: 20px;">30daysJS</a> <a href="/tags/blog/" style="font-size: 20px;">blog</a> <a href="/tags/movie/" style="font-size: 10px;">movie</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/python3/" style="font-size: 20px;">python3</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/04/08/relax1/">Andhadhun.调音师</a>
          </li>
        
          <li>
            <a href="/2019/04/08/30day16/">30daysJS 16 JS监听鼠标并改变文字阴影</a>
          </li>
        
          <li>
            <a href="/2019/04/08/30day15/">30daysJS 15 JS调用与建立Local Storage</a>
          </li>
        
          <li>
            <a href="/2019/04/08/python0/">Python学习指南</a>
          </li>
        
          <li>
            <a href="/2019/04/08/python1/">python3爬取淘宝搜索</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 wenz<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>